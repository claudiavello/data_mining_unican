{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Minería de Datos (Máster en Ciencia de Datos)\n",
    "# Práctica: k-NN\n",
    "### Rodrigo Manzanas, Ana Casanueva  \n",
    "#### Departamento de Matemática Aplicada y Ciencias de la Computación (Universidad de Cantabria)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se explicó en la sesión de teoría, la técnica k-NN puede utilizarse tanto para clasificación como para regresión. En esta práctica vamos a trabajar con el dataset *MNIST* para clasificación de dígitos en imágenes y con datos meteorológicos para predecir la lluvia diaria en Lisboa. Utilizaremos los paquetes `class`, `FNN`y `caret`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-NN para clasificación\n",
    "Para este ejemplo utilizaremos el dataset *MNIST*. Como ya habéis visto, se trata de reconocer dígitos (0, 1, ..., 9) en una colección de imágenes. En primer lugar cargamos el dataset (sólo la parte de train) con la función *read.csv* y convertimos a factor nuestra variable objetivo (primera columna)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## loading dataset\n",
    "data = read.csv(\"/home/rodrigo/work/DOCENCIA/2024-2025/M1966_mineria_datos_data_science/S10_kNN/data/MNIST_train.csv\")\n",
    "\n",
    "## converting target variable to factor\n",
    "data[,1] = as.factor(data[,1])\n",
    "#str(data)\n",
    "#head(data, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para entender mejor qué aspecto tienen las imágenes que contiene el dataset, vamos a dibujar un par de ellas (las que tú quieras) en un *p-color*. Utiliza para ello las funciones `image.plot` (paquete `fields`) y `fliplr` (paquete `pracma`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(fields)\n",
    "library(pracma)\n",
    "\n",
    "# p-colors\n",
    "par(mfrow = c(1, 2))\n",
    "image.plot(1:28, 1:28, fliplr(matrix(as.numeric(data[30, -1]), \n",
    "                                  nrow = 28, ncol = 28, byrow = F)), \n",
    "        xlab = \"pixel\", ylab = \"pixel\")\n",
    "\n",
    "image.plot(1:28, 1:28, fliplr(matrix(as.numeric(data[50, -1]), \n",
    "                                  nrow = 28, ncol = 28, byrow = F)), \n",
    "        xlab = \"pixel\", ylab = \"pixel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puesto que el dataset es muy grande (casi 4000 muestras), trabajaremos sólo con las 2000 primeras instancias. De entre éstas, nuestro dataset de train estará formado por las 1500 primeras (75% del total de datos), y el de test por las 500 restantes (25% del total de datos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train/test partition\n",
    "indtrain = 1:1500\n",
    "indtest = 1501:2000\n",
    "data.train = data[indtrain,] \n",
    "data.test = data[indtest,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio:** Calcula, en la muestra de train, cuántas observaciones tienes para cada dígito. ¿Dírias que hay desbalanceo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n.digit = sapply(0:9, function(dig) sum(data.train[, 1] == dig))\n",
    "bp = barplot(n.digit, ylim = c(0, 200), xlab = \"digit\", ylab = \"no. occurreces\")\n",
    "axis(1, at = bp, labels = 0:9)\n",
    "grid(nx = NA, ny = NULL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio:** Utiliza la función `knn` (paquete `class`) para clasificar los dígitos del test, considerando para ello el vecino más cecano en el train. Calcula la tasa de aciertos (total) sobre el test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## k-NN (with k=1)\n",
    "library(class)\n",
    "pred = knn(data.train[,-1], data.test[,-1], data.train$label, k = 1)\n",
    "sum(pred == data.test$label) / length(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio:** Como acabas de ver, el error \"global\" de clasificación del método k-NN (con k=1) está en torno al 10%. Dibuja un barplot con la tasa de aciertos para cada dígito (0, 1, ..., 9) que nos permita hacer un ranking con los mejor y peor clasificados. ¿Cuál es el dígito que mejor se clasifica? ¿Y el peor? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## best and worst classified digits\n",
    "acc.digit = rep(NA, 10)\n",
    "for (digit in 0:9) {\n",
    "  ind.digit = which(data.test$label == digit) \n",
    "  acc.digit[digit + 1] = sum(pred[ind.digit] == digit) / length(ind.digit)\n",
    "}\n",
    "bp = barplot(acc.digit, ylim = c(0, 1), xlab = \"digit\", ylab = \"ACC\")\n",
    "axis(1, at = bp, labels = 0:9)\n",
    "grid(nx = NA, ny = NULL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio:** Obtén la matriz de confusión (función `confusionMatrix` del paquete `caret`). ¿Se confirman tus conclusiones? ¿A qué crees que pueden deberse?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(caret)\n",
    "confusionMatrix(pred, as.factor(data.test$label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio:** Para tratar de entender un poco mejor estos resultados, visualiza los nueve primeros \"1\" y los nueve primeros \"8\" que aparecen en el dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## nine first \"1\" images\n",
    "ind1 = which(data[,1] == 1)\n",
    "par(mfrow = c(3,3))\n",
    "for (i in 1:9) {\n",
    "  image.plot(1:28, 1:28, fliplr(matrix(as.numeric(data[ind1[i], -1]), \n",
    "                                  nrow = 28, ncol = 28, byrow = F)), \n",
    "        xlab = \"pixel\", ylab = \"pixel\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## nine first \"8\" images\n",
    "ind8 = which(data[,1] == 8)\n",
    "par(mfrow = c(3,3))\n",
    "for (i in 1:9) {\n",
    "  image.plot(1:28, 1:28, fliplr(matrix(as.numeric(data[ind8[i], -1]), \n",
    "                                  nrow = 28, ncol = 28, byrow = F)), \n",
    "        xlab = \"pixel\", ylab = \"pixel\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio:** Para evaluar cómo influye la elección del parámetro k en nuestros resultados, repite el mismo experimento pero considerando todos los *k* entre 1 y 20. ¿Se obtiene alguna conclusión general sobre el efecto que tiene la elección de *k*? ¿Es ese efecto más importante para algún dígito concreto?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## effect of changing k\n",
    "n.k = 1:20\n",
    "acc.kd = matrix(NA, length(n.k), 10)\n",
    "for (k in n.k) {\n",
    "  print(paste(\"... predicting for\", k, \"nearest neighbors ...\") )\n",
    "  pred = knn(data.train[,-1], data.test[,-1], data.train$label, k = k)\n",
    "  \n",
    "  acc.digit = rep(NA, 10)\n",
    "  for (digit in 0:9) {\n",
    "    ind.digit = which(data.test$label == digit) \n",
    "    acc.digit[digit+1] = sum(pred[ind.digit] == digit) / length(ind.digit)\n",
    "  }\n",
    "  acc.kd[which(n.k == k), ] = acc.digit\n",
    "}\n",
    "## boxplot\n",
    "boxplot(acc.kd, type = \"l\", lty = 1, \n",
    "        xlab = \"digit\", ylab = \"accuracy\", \n",
    "        names = 0:9)\n",
    "grid()\n",
    "\n",
    "## lineplot\n",
    "matplot(acc.kd, type = \"l\", lty = 1, col = rainbow(10),\n",
    "        xlab = \"k\", ylab = \"acc\")\n",
    "legend(\"topright\", as.character(0:9), \n",
    "       col = rainbow(10), lty = 1)\n",
    "grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-NN para regresión \n",
    "Como ya se explicó, en el *downscaling* estadístico se trata de predecir variables meteorológicas a escala local (por ejemplo la precipitación y/o temperatura observada en una localidad concreta) a partir de variables de larga escala dadas por un modelo númerico del clima cuya resolución espacial es grosera (por ejemplo, la presión o los vientos en dominios sinópticos). En este ejemplo utilizaremos la técnica k-NN para intentar predecir la lluvia diaria observada en Lisboa (predictando) a partir de un conjunto de variables de larga escala (predictores).  \n",
    "En primer lugar cargamos el dataset *meteo.csv*. Como el dataset es muy grande nos quedaremos sólo con los primeros 2000 días (filas). Además, eliminaremos la primera columna (es un simple contador). A partir de este momento tendremos un dataset (llámalo *df*) con 2000 filas y 321 columnas (compruébalo). La primera columna será nuestra variable objetivo: la precipitación diaria en Lisboa durante el período 1979-2008. Las 320 columnas restantes serán nuestros predictores: 8 variables de larga escala, definidas sobre una malla de 40 puntos (8 en la longitud y 5 en la latitud) que cubre la Península Ibérica.\n",
    "\n",
    "- Altura geopotencial en 500 hPa (columnas 2:41)\n",
    "- Temperatura del aire en 850 hPa (columnas 42:81), 700 hPa (columnas 82:121) y 500 hPa (columnas 122:161)\n",
    "- Temperatura del aire en superficie (columnas 162:201)\n",
    "- Humedad específica del aire en 850 hPa (columnas 202:241) y 500 hPa (columnas 242:281)\n",
    "- Presión al nivel del mar (columnas 282:321)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## loading data\n",
    "data = read.csv(\"/home/rodrigo/work/DOCENCIA/2024-2025/M1966_mineria_datos_data_science/S10_kNN/data/meteo.csv\")\n",
    "df = data[1:2000, -1]; rm(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por comodidad, renombramos como *precip* nuestra variable objetivo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames(df)[1] = \"precip\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Además, para entender un poco mejor qué tipo de datos contiene el dataset, vamos a dibujar en un mapa la temperatura del aire en 850 hPa (columnas 42:81) y la presión al nivel del mar (columnas 282:321) para el primer día de registros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lon = seq(-10, 4, 2) # 2º resolution\n",
    "lat = seq(36, 44, 2) # 2º resolution\n",
    "\n",
    "library(maps)\n",
    "par(mfrow = c(1, 2))\n",
    "image.plot(x = lon, y = lat, matrix(as.numeric(df[1, 42:81]), \n",
    "                                     nrow = length(lon), \n",
    "                                     ncol = length(lat), byrow = T),\n",
    "           main = \"T850\")\n",
    "map(add = T)  # overlapping map\n",
    "\n",
    "image.plot(x = lon, y = lat, matrix(as.numeric(df[1, 282:321]), \n",
    "                                    nrow = length(lon), \n",
    "                                    ncol = length(lat), byrow = T),\n",
    "           main = \"SLP\")\n",
    "map(add = T)  # overlapping map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya que las vamos a necesitar posteriormente, crearemos una nueva variable *y* (vector predictando con la precipitación en Lisboa) y otra *x* (matriz con los predictores de larga escala)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## new variables x and y\n",
    "y = df[, 1]  # predictand (vector)\n",
    "x = df[, -1]  # predictors (matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio:** Para visualizar los datos, dibuja en una figura la serie diaria de precipitación observada y en otra el valor promedio de cada uno de los 320 predictores.\n",
    "¿Qué dirías sobre los predictores? ¿Crees que habría que tener algún cuidado especial al trabajar con la técnica k-NN en este caso?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## data visualization\n",
    "par(mfrow = c(2, 1))\n",
    "plot(y, xlab = \"days\", ylab = \"precip (mm)\", type = \"l\"); grid()\n",
    "plot(colMeans(x), cex = 0.1, xlab = \"predictors\", ylab = \"units\"); grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuestro siguiente paso será dividir el dataset total en dos subconjuntos independientes de train y test (75% y 25%, respectivamente), escogidos aleatoriamente. Por comodidad, crea las variables *df.train*, *df.test*, *x.train*, *y.train*, *x.test*, *y.test*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train/test partition\n",
    "n = nrow(df)\n",
    "indtrain = sample(1:n, round(0.75*n))\n",
    "indtest = setdiff(1:n, indtrain)\n",
    "\n",
    "# 75% train\n",
    "df.train = df[indtrain, ]\n",
    "x.train = x[indtrain, ]\n",
    "y.train = y[indtrain]\n",
    "\n",
    "# 25% test\n",
    "df.test = df[indtest, ]\n",
    "x.test = x[indtest, ]\n",
    "y.test = y[indtest]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya estamos en condiciones de buscar el *k* óptimo para la técnica k-NN. Para ello emplearemos el paquete `caret` (método `knn`).   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio:** Trabaremos ahora con `caret`. En concreto, considera un marco de validación cruzada con 4 _folds_ sobre el dataset de train y barre todos los *k* desde 1 a 30 (revisa la documentación sobre el argumento `tuneGrid` de la función `train`). Recuerda que habrá que estandarizar los predictores (argumento `preProcess` de `train`). ¿Cómo varía la métrica de validación RMSE con *k*? ¿Por qué crees que ocurre esto? ¿Cuál es el *k* óptimo?   \n",
    "**Nota:** Puedes consultar la documentación del paquete `caret` aquí: https://topepo.github.io/caret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fitting the value of k with caret\n",
    "trctrl = trainControl(method = \"cv\", number = 4)  #4-fold CV\n",
    "knn.fit = train(precip ~ ., df.train,\n",
    "                method = \"knn\",\n",
    "                trControl = trctrl,\n",
    "                preProcess = c(\"center\", \"scale\"),\n",
    "                tuneGrid = expand.grid(k = 1:30))\n",
    "plot(knn.fit)\n",
    "knn.fit$bestTune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hemos visto que el RMSE disminuye con *k* (hasta un cierto punto). Pero para determinar cuán buena/mala es nuestra predicción no podemos fijarnos en una única medida, sino que debemos tener en cuenta un abanico más amplio de métricas que nos permitan caracterizar otros aspectos de la predicción que puedan ser de interés. En esta práctica consideraremos, además del RMSE, las siguientes métricas de validación:  \n",
    "\n",
    "* Tasa de aciertos (o *accuracy*): permite evaluar el evento binario *lluvia/no lluvia*. Se suele tomar la cantidad 0.1 mm como umbral para definir días de lluvia.\n",
    "* Correlación de Spearman: permite evaluar cuán bien la serie temporal predicha (completa) sigue la observación. Se puede calcular en `R` utilizando la función `cor`.\n",
    "* *Ratio* de varianzas: permite evaluar hasta qué punto la variabilidad total de nuestra predicción (serie completa) se asemeja a la observada. Se calcula como $\\frac{var(pred)}{var(obs}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio:** Utiliza el *k* óptimo que acabas de encontrar para predecir la lluvia en el test, y valida los resultados en función de estas 4 métricas. ¿Qué resultados obtienes? ¿Dirías que tu predicción es buena? ¿Mala? ¿Por qué?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## predictions for test\n",
    "pred = predict(knn.fit, df.test[, -1])\n",
    "\n",
    "## validation\n",
    "# RMSE\n",
    "rmse <- function(x, y) {\n",
    "    stopifnot(length(x) == length(y))\n",
    "    sqrt(mean((x - y)^2))\n",
    "}\n",
    "val.rmse = rmse(df.test$precip, pred)\n",
    "\n",
    "# Spearman correlation\n",
    "val.r = cor(df.test$precip, pred, method = \"spearman\")\n",
    "\n",
    "## accuracy binary\n",
    "acc.class = function(x, y) {\n",
    "  stopifnot(length(x) == length(y))\n",
    "  return(sum(diag(table(x, y))) / length(x))\n",
    "}\n",
    "val.bin = acc.class(ifelse(df.test$precip < 0.1, 0, 1), ifelse(pred < 0.1, 0, 1))\n",
    "\n",
    "# ratio of variances\n",
    "val.rv = var(pred) / var(df.test$precip)\n",
    "\n",
    "cbind(val.rmse, val.r, val.bin, val.rv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio:** A continuación, vamos a analizar cómo varían las 4 métricas de validación consideradas con *k*, pero esta vez apoyándonos en la función `knn.reg` (paquete `FNN`). Para ello, crea un bucle que barra todos los *k* desde 1 hasta 30 y calcula en cada iteración el RMSE, la correlación de Spearman, el accuracy (binario) y el ratio de varianzas. Haz este experimento sin escalar los predictores y escalándolos correctamente (usa para ello las funciones `preProcess` y `scale`). Grafica los resultados. ¿Qué conclusiones obtienes? ¿Cuál sería para tí un *k* óptimo?   \n",
    "**Nota:** Utiliza la función `knn.reg` (paquete `FNN`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(FNN)\n",
    "\n",
    "## scaling the predictors\n",
    "params.scaling = preProcess(x.train, method = c(\"center\", \"scale\"))\n",
    "x.train.scaled = scale(x.train, \n",
    "                       center = params.scaling$mean, scale = params.scaling$std)\n",
    "x.test.scaled = scale(x.test, \n",
    "                      center = params.scaling$mean, scale = params.scaling$std)\n",
    "\n",
    "val.rmse.without.scaling = rep(NA, 30)\n",
    "val.r.without.scaling = rep(NA, 30)\n",
    "val.bin.without.scaling = rep(NA, 30)\n",
    "val.rv.without.scaling = rep(NA, 30)\n",
    "\n",
    "val.rmse.with.scaling = rep(NA, 30)\n",
    "val.r.with.scaling = rep(NA, 30)\n",
    "val.bin.with.scaling = rep(NA, 30)\n",
    "val.rv.with.scaling = rep(NA, 30)\n",
    "for (k in 1:30) {\n",
    "  print(sprintf(\"... trying k = %d ...\", k))\n",
    "  \n",
    "  ## predicting\n",
    "  pred.without.scaling = knn.reg(train = x.train, test = x.test, \n",
    "                                 y = y.train, k = k)\n",
    "  pred.with.scaling = knn.reg(train = x.train.scaled, test = x.test.scaled, \n",
    "                              y = y.train, k = k)\n",
    "  \n",
    "  ## validating (without predictor scaling)\n",
    "  val.rmse.without.scaling[k] = rmse(y.test, pred.without.scaling$pred)\n",
    "  val.r.without.scaling[k] = cor(y.test, pred.without.scaling$pred, method = \"spearman\")\n",
    "  val.bin.without.scaling[k] = acc.class(ifelse(y.test < 0.1, 0, 1), \n",
    "                                         ifelse(pred.without.scaling$pred < 0.1, 0, 1))\n",
    "  val.rv.without.scaling[k] = var(pred.without.scaling$pred) / var(y.test)\n",
    "  \n",
    "  ## validating (with predictor scaling)\n",
    "  val.rmse.with.scaling[k] = rmse(y.test, pred.with.scaling$pred)\n",
    "  val.r.with.scaling[k] = cor(y.test, pred.with.scaling$pred, method = \"spearman\")\n",
    "  val.bin.with.scaling[k] = acc.class(ifelse(y.test < 0.1, 0, 1), \n",
    "                                      ifelse(pred.with.scaling$pred < 0.1, 0, 1))\n",
    "  val.rv.with.scaling[k] = var(pred.with.scaling$pred) / var(y.test)\n",
    "}\n",
    "\n",
    "## plotting\n",
    "par(mfrow = c(2,2))\n",
    "matplot(1:30, cbind(val.rmse.without.scaling, val.rmse.with.scaling),\n",
    "        type = \"o\", pch = 19, cex = 0.5, xlab = \"k\", ylab = \"RMSE\")\n",
    "legend(\"topright\", c(\"Without scaling\", \"With scaling\"), \n",
    "       col = c(\"black\", \"red\"), lty = 1); grid()\n",
    "matplot(1:30, cbind(val.r.without.scaling, val.r.with.scaling),\n",
    "        type = \"o\", pch = 19, cex = 0.5, xlab = \"k\", ylab = \"Spearman corr.\")\n",
    "legend(\"topright\", c(\"Without scaling\", \"With scaling\"), \n",
    "       col = c(\"black\", \"red\"), lty = 1); grid()\n",
    "matplot(1:30, cbind(val.bin.without.scaling, val.bin.with.scaling), \n",
    "        type = \"o\", pch = 19, cex = 0.5, xlab = \"k\", ylab = \"Acc. binary\")\n",
    "legend(\"topright\", c(\"Without scaling\", \"With scaling\"), \n",
    "       col = c(\"black\", \"red\"), lty = 1); grid()\n",
    "matplot(1:30, cbind(val.rv.without.scaling, val.rv.with.scaling),\n",
    "        type = \"o\", pch = 19, cex = 0.5, xlab = \"k\", ylab = \"RV\")\n",
    "legend(\"topright\", c(\"Without scaling\", \"With scaling\"), \n",
    "       col = c(\"black\", \"red\"), lty = 1); grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la sesión de teoría se comentó que es frecuente el uso de técnicas avanzadas (como el análisis de Componentes Principales) que permiten reducir la dimensionalidad del problema sin pérdida de información efectiva. Estas técnicas se verán en detalle en la asignatura _Estadística para la Ciencia de Datos_. De momento, para reducir el número de predictores que entran en nuestro modelo, nos limitaremos a efectuar un entresacado (no informado) de variables. En concreto, escogeremos una de cada cinco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## not informed selection\n",
    "nx = ncol(x.train)\n",
    "ind.extr = seq(1, nx, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra forma un poco más dirigida de reducir la dimensionalidad de nuestro problema consiste en realizar un análisis de correlaciones. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio:** Calcula la correlación de Spearman entre nuestra variable objetivo (lluvia) y todas las variables predictoras (larga escala) disponibles. La idea es que, cuanto más fuerte sea esta correlación, mayor es el vínculo físico entre predictando y predictor, y por tanto, más útil es la información que nos aporta ese predictor. Este análisis nos permite descartar aquellos predictores cuya correlación con el predictando no supere cierto umbral (nótese, sin embargo, que no se resolvería el problema de la colinealidad en los predictores, que puede afectar negativamente a otro tipo de técnicas como los modelos lineales). Siguiendo esta idea, analiza la correlación existente entre nuestro predictando y los 320 predictores disponibles, y elimina aquellos que muestren valores entre -0.4 y 0.4 ¿Cuánto se ha reducido la dimensionalidad del problema?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## informed selection\n",
    "r.xy = c()\n",
    "for (ivar in 2:nx) {\n",
    "  r.xy[ivar] = cor(y.train, x.train[, ivar], method = \"spearman\")\n",
    "}\n",
    "plot(r.xy, ylim = c(-0.6, 0.6), pch = 19, cex = 0.5, \n",
    "     xlab = \"predictor\", ylab = \"Spearman corr. with precip\")\n",
    "grid()\n",
    "\n",
    "ind.sele = which(abs(r.xy) > 0.4)\n",
    "length(ind.sele)\n",
    "points(ind.sele, r.xy[ind.sele], col = \"red\", cex = 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio:** Obtén ahora la predicción en el test para el caso del entresacado no informado de predictores y para la selección informada de los mismos (recuerda escalar correctamente), para valores de *k* desde 1 hasta 30. Apóyate para ello en la función `knn.reg`. Evalúa estas predicciones en función de las 4 métricas de validación consideradas en el análisis anterior. Plotea en el mismo gráfico los resultados obtenidos para 1) todos los predictores, 2) el entresacado no informado y 3) la selección informada. ¿Qué conclusiones obtienes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## not informed selection\n",
    "x.train.extr = x.train[, ind.extr]\n",
    "x.test.extr = x.test[, ind.extr]\n",
    "params.scaling.extr = preProcess(x.train.extr, method = c(\"center\", \"scale\"))\n",
    "x.train.extr.scaled = scale(x.train.extr,\n",
    "                            center = params.scaling.extr$mean, \n",
    "                            scale = params.scaling.extr$std)\n",
    "x.test.extr.scaled = scale(x.test.extr, \n",
    "                           center = params.scaling.extr$mean, \n",
    "                           scale = params.scaling.extr$std)\n",
    "\n",
    "## informed selection\n",
    "x.train.sele = x.train[, ind.sele]\n",
    "x.test.sele = x.test[, ind.sele]\n",
    "params.scaling.sele = preProcess(x.train.sele, method = c(\"center\", \"scale\"))\n",
    "x.train.sele.scaled = scale(x.train.sele,\n",
    "                            center = params.scaling.sele$mean, \n",
    "                            scale = params.scaling.sele$std)\n",
    "x.test.sele.scaled = scale(x.test.sele, \n",
    "                           center = params.scaling.sele$mean, \n",
    "                           scale = params.scaling.sele$std)\n",
    "\n",
    "\n",
    "val.extr.rmse = rep(NA, 30)\n",
    "val.extr.r = rep(NA, 30)\n",
    "val.extr.bin = rep(NA, 30)\n",
    "val.extr.rv = rep(NA, 30)\n",
    "\n",
    "val.sele.rmse = rep(NA, 30)\n",
    "val.sele.r = rep(NA, 30)\n",
    "val.sele.bin = rep(NA, 30)\n",
    "val.sele.rv = rep(NA, 30)\n",
    "\n",
    "for (k in 1:30) {\n",
    "  print(sprintf(\"... trying k = %d ...\", k))\n",
    "  \n",
    "  ## not informed selection\n",
    "  pred.extr = knn.reg(train = x.train.extr.scaled, test = x.test.extr.scaled, \n",
    "                      y = y.train, k = k)\n",
    "  val.extr.rmse[k] = rmse(y.test, pred.extr$pred)\n",
    "  val.extr.r[k] = cor(y.test, pred.extr$pred, method = \"spearman\")\n",
    "  val.extr.bin[k] = acc.class(ifelse(y.test < 0.1, 0, 1), \n",
    "                              ifelse(pred.extr$pred < 0.1, 0, 1))\n",
    "  val.extr.rv[k] = var(pred.extr$pred) / var(y.test)\n",
    "  \n",
    "  ## informed selection\n",
    "  pred.sele = knn.reg(train = x.train.sele.scaled, test = x.test.sele.scaled,\n",
    "                      y = y.train, k = k)\n",
    "  val.sele.rmse[k] = rmse(y.test, pred.sele$pred)\n",
    "  val.sele.r[k] = cor(y.test, pred.sele$pred, method = \"spearman\")\n",
    "  val.sele.bin[k] = acc.class(ifelse(y.test < 0.1, 0, 1), \n",
    "                              ifelse(pred.sele$pred < 0.1, 0, 1))\n",
    "  val.sele.rv[k] = var(pred.sele$pred) / var(y.test)    \n",
    "}\n",
    "\n",
    "## plotting\n",
    "par(mfrow = c(2,2))\n",
    "matplot(1:30, cbind(val.rmse.with.scaling, val.extr.rmse, val.sele.rmse), lty = 1, type = \"o\", pch = 19, cex = 0.5, col = c(\"black\", \"red\", \"green\"), xlab = \"k\", ylab = \"RMSE\"); grid()\n",
    "matplot(1:30, cbind(val.r.with.scaling, val.extr.r, val.sele.r), lty = 1, type = \"o\", pch = 19, cex = 0.5, col = c(\"black\", \"red\", \"green\"), xlab = \"k\", ylab = \"Spearman corr.\"); grid()\n",
    "matplot(1:30, cbind(val.bin.with.scaling, val.extr.bin, val.sele.bin), lty = 1, type = \"o\", pch = 19, cex = 0.5, col = c(\"black\", \"red\", \"green\"), xlab = \"k\", ylab = \"Acc. binary\"); grid()\n",
    "matplot(1:30, cbind(val.rv.with.scaling, val.extr.rv, val.sele.rv), lty = 1, type = \"o\", pch = 19, cex = 0.5, col = c(\"black\", \"red\", \"green\"), xlab = \"k\", ylab = \"RV\"); grid()\n",
    "legend(\"topright\", c(\"all\", \"not informed\", \"informed\"), lty = 1, col = c(\"black\", \"red\", \"green\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
