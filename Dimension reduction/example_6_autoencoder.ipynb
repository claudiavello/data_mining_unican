{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e18ecbc-c9e9-472e-a76b-1cfd1c44ff7a",
   "metadata": {},
   "source": [
    "Autoencoder\n",
    "===\n",
    "\n",
    "Data mining: Dimensionality reduction  \n",
    "Author: Steven Van Vaerenbergh  \n",
    "Universidad de Cantabria\n",
    "\n",
    "Adapted from https://towardsdatascience.com/how-autoencoders-outperform-pca-in-dimensionality-reduction-1ae44c68b42f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee4b0e0d-e865-4c16-8b6a-adb3a57917f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in /Users/claudiavello/.pyenv/versions/datamining/lib/python3.12/site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /Users/claudiavello/.pyenv/versions/datamining/lib/python3.12/site-packages (from seaborn) (2.0.2)\n",
      "Requirement already satisfied: pandas>=1.2 in /Users/claudiavello/.pyenv/versions/datamining/lib/python3.12/site-packages (from seaborn) (2.2.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /Users/claudiavello/.pyenv/versions/datamining/lib/python3.12/site-packages (from seaborn) (3.10.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/claudiavello/.pyenv/versions/datamining/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/claudiavello/.pyenv/versions/datamining/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/claudiavello/.pyenv/versions/datamining/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/claudiavello/.pyenv/versions/datamining/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/claudiavello/.pyenv/versions/datamining/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /Users/claudiavello/.pyenv/versions/datamining/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/claudiavello/.pyenv/versions/datamining/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/claudiavello/.pyenv/versions/datamining/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/claudiavello/.pyenv/versions/datamining/lib/python3.12/site-packages (from pandas>=1.2->seaborn) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/claudiavello/.pyenv/versions/datamining/lib/python3.12/site-packages (from pandas>=1.2->seaborn) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/claudiavello/.pyenv/versions/datamining/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae78533f-5f6f-4985-a60c-785d22adff6a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'distutils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mnist\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtime\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m time\n",
      "File \u001b[0;32m~/.pyenv/versions/datamining/lib/python3.12/site-packages/tensorflow/__init__.py:30\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124;03mTop-level module of TensorFlow. By convention, we refer to this module as\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03m`tf` instead of `tensorflow`, following the common practice of importing\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;124;03mthis file with a file generated from [`api_template.__init__.py`](https://www.github.com/tensorflow/tensorflow/blob/master/tensorflow/api_template.__init__.py)\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# pylint: disable=g-bad-import-order,protected-access,g-import-not-at-top\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdistutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_distutils\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mimportlib\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01minspect\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_inspect\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'distutils'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0dded0c-f21c-4df1-87d1-14a5922d5f3c",
   "metadata": {},
   "source": [
    "## Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "273608a0-e3b6-4099-b4b6-92e0fd494982",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mnist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m (train_images, train_labels), (test_images, test_labels) \u001b[38;5;241m=\u001b[39m \u001b[43mmnist\u001b[49m\u001b[38;5;241m.\u001b[39mload_data()\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Reshape data\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mnist' is not defined"
     ]
    }
   ],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Reshape data\n",
    "import numpy as np\n",
    "\n",
    "train_images = np.reshape(train_images, (-1, 784))\n",
    "test_images = np.reshape(test_images, (-1, 784))\n",
    "\n",
    "# Normalize data\n",
    "train_images = train_images.astype('float32') / 255\n",
    "test_images = test_images.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4f4a34-118e-4fbe-ae53-33071dbbcce0",
   "metadata": {},
   "source": [
    "## Apply PCA with only two components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe225b56-e93d-4099-b9a9-819b6a8698a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(train_images)\n",
    "compressed_images = pca.transform(test_images)\n",
    "recovered_images = pca.inverse_transform(compressed_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0c0b99-9133-4805-a1e4-cfb8a1d1b67a",
   "metadata": {},
   "source": [
    "## Visualize compressed MNIST digits after PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b4805b-da66-44bd-a2a9-d26a6707fc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize compressed MNIST digits after PCA\n",
    "n = 5\n",
    "plt.figure(figsize=(9, 2))\n",
    "for i in range(n):\n",
    "  ax = plt.subplot(1, n, i+1)\n",
    "  plt.imshow(recovered_images[i].reshape(28, 28), cmap=\"gray\")\n",
    "  ax.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6dad310-3921-4c99-998d-c53a624a1f8c",
   "metadata": {},
   "source": [
    "## Visualize test data using the two principal components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84df548c-dc64-499e-b93a-477044435a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "sns.scatterplot(x=compressed_images[:,0],\n",
    "                y=compressed_images[:,1],\n",
    "                hue=test_labels, palette='tab10')\n",
    "\n",
    "plt.xlabel(\"First principal component\")\n",
    "plt.ylabel(\"Second principal component\")\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.01, 1),\n",
    "           borderaxespad=0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1282a5-d7f3-4387-9e96-f82d0875c50b",
   "metadata": {},
   "source": [
    "## Define the Autoencoder architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7793d8-2dd4-4bb6-a4c7-49e3434a07a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model, Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "input_dim = 28*28\n",
    "latent_vec_dim = 2\n",
    "\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "\n",
    "# Define the autoencoder architecture\n",
    "# First build the encoder\n",
    "enc_layer_1 = Dense(500, activation='sigmoid')(input_layer)\n",
    "enc_layer_2 = Dense(300, activation='sigmoid')(enc_layer_1)\n",
    "enc_layer_3 = Dense(100, activation='sigmoid')(enc_layer_2)\n",
    "enc_layer_4 = Dense(latent_vec_dim, activation='tanh')(enc_layer_3)\n",
    "encoder = enc_layer_4\n",
    "\n",
    "# Then build the decoder\n",
    "dec_layer_1 = Dense(100, activation='sigmoid')(encoder)\n",
    "dec_layer_2 = Dense(300, activation='sigmoid')(dec_layer_1)\n",
    "dec_layer_3 = Dense(500, activation='sigmoid')(dec_layer_2)\n",
    "dec_layer_4 = Dense(input_dim, activation='sigmoid')(dec_layer_3)\n",
    "decoder = dec_layer_4\n",
    "\n",
    "# Connect both encoder and decoder\n",
    "autoencoder = Model(input_layer, decoder, name=\"Deep_Autoencoder\")\n",
    "\n",
    "# Latent representation (Optional)\n",
    "latent_model = Model(input_layer, encoder)\n",
    "\n",
    "# Get summary\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d1bde9-2b96-4aee-895e-c758ecff24d5",
   "metadata": {},
   "source": [
    "## Compile, train and monitor the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fb9c4b-d3c7-47f7-a651-25c37931ce96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the autoencoder model\n",
    "autoencoder.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "\n",
    "# Train the autoencoder with MNIST data\n",
    "t0 = time()\n",
    "history = autoencoder.fit(train_images, train_images, epochs=70, batch_size=128,\n",
    "                          shuffle=True, validation_data=(test_images, test_images))\n",
    "t1 = time()\n",
    "print(\"Autoencoder: %.2g sec\" % (t1 - t0))\n",
    "\n",
    "# Plot training and validation loss scores\n",
    "# against the number of epochs.\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'], label='Train')\n",
    "plt.plot(history.history['val_loss'], label='Validation')\n",
    "plt.ylabel('Binary Cross Entropy Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.title('Autoencoder Reconstruction Loss', pad=13)\n",
    "plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a04612d-11be-4c84-aa48-ea95cd09dc3e",
   "metadata": {},
   "source": [
    "## Visualize compressed MNIST digits after autoencoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ed22bb-2a76-44cc-8ed1-b6b787290b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_images = autoencoder.predict(test_images)\n",
    "n = 5\n",
    "plt.figure(figsize=(9, 2))\n",
    "for i in range(n):\n",
    "  ax = plt.subplot(1, n, i+1)\n",
    "  plt.imshow(compressed_images[i].reshape(28, 28), cmap=\"gray\")\n",
    "  ax.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17236cae-fec6-42c5-9889-ff3892003485",
   "metadata": {},
   "source": [
    "## Visualize test data in the latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b2bd39-d08b-47cb-9be9-c46d689e8912",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_representation = latent_model.predict(test_images)\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "sns.scatterplot(x=latent_representation[:,0],\n",
    "                y=latent_representation[:,1],\n",
    "                hue=test_labels, palette='tab10')\n",
    "\n",
    "plt.xlabel(\"Encoder first dimension\")\n",
    "plt.ylabel(\"Encoder second dimension\")\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.01, 1),\n",
    "           borderaxespad=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922b764c-7812-4f5b-813b-343dfe38e065",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "(Python) Data Mining",
   "language": "python",
   "name": "datamining"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
